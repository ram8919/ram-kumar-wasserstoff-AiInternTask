# -*- coding: utf-8 -*-
"""Building an AI Pipeline for Image Segmentation and Object  Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GRhOOmAsGjA5zN8ztcwARMRhmY_dilnF
"""

# Step 1: Image Segmentation

import torch
import torchvision
from torchvision.models.detection import maskrcnn_resnet50_fpn
import torchvision.transforms as T
from PIL import Image
import matplotlib.pyplot as plt

def get_model():
    model = maskrcnn_resnet50_fpn(pretrained=True)
    model.eval()
    return model

def get_prediction(img_path, model, threshold=0.5):
    img = Image.open('/content/cycle.jpg').convert("RGB")
    transform = T.Compose([T.ToTensor()])
    img = transform(img).unsqueeze(0)
    with torch.no_grad():
        pred = model(img) # Make sure this line is inside the 'with' block
        pred_score = list(pred[0]['scores'].detach().numpy())
        pred_t = [pred_score.index(x) for x in pred_score if x > threshold]
        masks = (pred[0]['masks'] > 0.5).squeeze().detach().cpu().numpy()
    masks = masks[:len(pred_t)]
    return masks, pred[0]['labels'], pred[0]['boxes']

def plot_segmented_image(path='/content/cycle.jpg', masks=None):
    img = Image.open(path).convert("RGB")
    plt.imshow(img)
    for mask in masks:
        plt.imshow(mask, alpha=0.5)
    plt.show()

if __name__ == "__main__":
    model = get_model()
    img_path = "/content/cycle.jpg"
    masks, labels, boxes = get_prediction(img_path, model)
    plot_segmented_image(img_path, masks)

# Step 2: Object Extraction and Storage

import cv2
import numpy as np
import os
from PIL import Image

def save_extracted_objects(img_path, masks, output_dir="segmented_objects"):
    img = cv2.imread(img_path)
    os.makedirs(output_dir, exist_ok=True)
    object_id = 1
    for mask in masks:
        obj = cv2.bitwise_and(img, img, mask=mask.astype(np.uint8))
        cv2.imwrite(f"{output_dir}/object_{object_id}.png", obj)
        object_id += 1

if __name__ == "__main__":
    img_path = "/content/cycle.jpg"
    masks, _, _ = get_prediction(img_path, model)
    save_extracted_objects(img_path, masks)

# Step 3: Object Identification

import torch
from PIL import Image
import torchvision.transforms as T
import os

def identify_objects(img_path, model):
    # Check if the file exists before attempting to open it
    if not os.path.exists(img_path):
        print(f"Error: File not found - {img_path}")
        return None  # Or handle the error as needed

    img = Image.open(img_path).convert("RGB")

    # Resize and pad the image to a standard size for YOLOv5
    transform = T.Compose([
        T.Resize((640, 640)),
        T.ToTensor()
    ])
    img = transform(img).unsqueeze(0)

    with torch.no_grad():
        pred = model(img)

    return pred

if __name__ == "__main__":
    # Load the YOLOv5 model
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
    img_path = "/content/cycle.jpg"  # Verify this path
    pred = identify_objects(img_path, model)
    print(pred)

# Step 4: Text/Data Extraction from Objects

!pip install pytesseract
!pip install Pillow
!apt-get install tesseract-ocr
!which tesseract
import pytesseract
from PIL import Image
import os

# Find the correct path to the Tesseract executable
pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'

def extract_text(img_path):
    # Check if path is a directory and process images within
    if os.path.isdir(img_path):
        for filename in os.listdir(img_path):
            if filename.endswith(('.jpg', '.jpeg', '.png')):
                image_path = os.path.join(img_path, filename)
                img = Image.open(image_path)
                text = pytesseract.image_to_string(img)
                print(f"Text from {filename}: {text}")
    else:
        img = Image.open(img_path)
        text = pytesseract.image_to_string(img)
        return text

if __name__ == "__main__":
    img_path = "/content/segmented_objects"
    extract_text(img_path)

# Step 5: Summarize Object Attributes

from transformers import pipeline

def summarize_text(text):
    summarizer = pipeline("summarization")
    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)
    return summary[0]['summary_text']

if __name__ == "__main__":
    # Corrected path - removed 'data/' from the beginning
    text = extract_text("segmented_objects/object_1.png")
    summary = summarize_text(text)
    print(summary)

# Step 6: Data Mapping

import json
import os

def map_data_to_objects(data):
    mapped_data = {}
    for obj_id, details in data.items():
        mapped_data[obj_id] = details
    return mapped_data

if __name__ == "__main__":
    data = {
        "object_1": {
            "description": "A sample description",
            "text": "Extracted text",
            "summary": "Summary of the text"
        }
    }
    mapped_data = map_data_to_objects(data)

    # Create the 'data/output' directory if it doesn't exist
    os.makedirs("data/output", exist_ok=True)

    with open("data/output/mapped_data.json", "w") as f:
        json.dump(mapped_data, f)

# Step 7: Output Generation

import matplotlib.pyplot as plt
import pandas as pd
import torch
import torchvision.transforms as T
from PIL import Image

def generate_output_image(img_path, masks):
    img = Image.open(img_path).convert("RGB")
    plt.imshow(img)
    # Check if masks is not empty and iterable before trying to iterate
    if masks:
        for mask in masks:
            plt.imshow(mask, alpha=0.5)
    plt.savefig("/content/cycle.jpg")

def generate_output_table(mapped_data):
    df = pd.DataFrame.from_dict(mapped_data, orient='index')
    df.to_csv("data/output/final_output.csv")

# Assuming 'get_prediction' is defined elsewhere and returns masks, _, _
def get_prediction(img_path, model, threshold=0.5):
    # Load the image and apply necessary transformations
    img = Image.open(img_path).convert("RGB")

    # Resize the image to a standard size that is compatible with the model
    img = img.resize((640, 640))

    transform = T.Compose([
        T.ToTensor(),
    ])
    img = transform(img).unsqueeze(0)

    # Perform inference
    with torch.no_grad():
        pred = model(img)


    masks = []

    return masks, None, None

if __name__ == "__main__":
    # Load the YOLOv5 model (ensure it's loaded correctly)
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
    img_path = "/content/cycle.jpg"
    masks, _, _ = get_prediction(img_path, model)  # Call get_prediction
    generate_output_image(img_path, masks)
    with open("data/output/mapped_data.json", "r") as f:
        mapped_data = json.load(f)
    generate_output_table(mapped_data)

def get_prediction(img_path, model, threshold=0.5):
    img = Image.open(img_path).convert("RGB")
    img = transforms.ToTensor()(img)
    img = img.unsqueeze(0) # Add batch dimension

    with torch.no_grad():
        pred = model(img)
        pred_score = pred[0]['scores'].detach().numpy()
        pred_t = [i for i, x in enumerate(pred_score) if x > threshold]
        masks = (pred[0]['masks'] > 0.5).squeeze().detach().cpu().numpy()

    boxes = [[(int(i[0]), int(i[1])), (int(i[2]), int(i[3]))]  for i in list(pred[0]['boxes'].detach().numpy())]
    labels = [CLASSES[i] for i in list(pred[0]['labels'].detach().numpy())]

    return masks, boxes, labels

!pip install streamlit
import streamlit as st
from PIL import Image

def main():
    st.title("AI Pipeline for Image Segmentation and Object Analysis")
    uploaded_file = st.file_uploader("Choose an image...", type="jpg")
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption='Uploaded Image.', use_column_width=True)
        st.write("")
        st.write("Running pipeline...")

        # Assume all functions from the above scripts are imported
        masks, labels, boxes = get_prediction(uploaded_file, model)
        plot_segmented_image(uploaded_file, masks)
        save_extracted_objects(uploaded_file, masks)
        mapped_data = {}  # Populate with results from steps 3-6
        generate_output_image(uploaded_file, masks)
        generate_output_table(mapped_data)

        st.image("data/output/final_output.png", caption='Final Output Image', use_column_width=True)
        st.dataframe(pd.read_csv("data/output/final_output.csv"))

if __name__ == "__main__":
    main()

# streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]

!streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py & npx localtunnel --port 8501